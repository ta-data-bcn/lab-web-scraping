{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "github = BeautifulSoup(page.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jason Quense'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name, works for all!!\n",
    "github.find_all(\"h1\", class_=\"h3 lh-condensed\")[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jquense'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user, works for all!!\n",
    "github.find_all(\"p\", class_=\"f4 text-normal mb-1\")[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jason Quense', 'Anurag Hazra', 'Gleb Bahmutov', 'Rick Bergfalk', 'Dan Field', 'Sébastien Eustace', 'Sebastián Ramírez', 'Mike Penz', '卡色', 'Jeff Sagal', 'Sascha Grunert', 'Brian Vaughn', 'Adam Johnson', 'Brian Douglas', 'Ashley Jeffs', 'Michael Waskom', 'Rob Garrison', 'Stephen Celis', 'Ariel Mashraki', 'Joël Galeran', 'Peter Pistorius', 'Philip Walton', 'Satyajit Sahoo', 'Leo Di Donato', 'Mr.doob']\n"
     ]
    }
   ],
   "source": [
    "names=[]\n",
    "for i in range(len(github.find_all(\"h1\", class_=\"h3 lh-condensed\"))):\n",
    "    names.append(github.find_all(\"h1\", class_=\"h3 lh-condensed\")[i].get_text().strip())\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jquense', 'anuraghazra', 'bahmutov', 'rickbergfalk', 'dnfield', 'sdispater', 'tiangolo', 'mikepenz', 'cipchk', 'sagalbot', 'saschagrunert', 'bvaughn', 'adamchainz', 'bdougie', 'Jeffail', 'mwaskom', 'Mottie', 'stephencelis', 'a8m', 'Jolg42', 'peterp', 'philipwalton', 'satya164', 'leodido', 'mrdoob']\n"
     ]
    }
   ],
   "source": [
    "users=[]\n",
    "for i in range(len(github.find_all(\"p\", class_=\"f4 text-normal mb-1\"))):\n",
    "    users.append(github.find_all(\"p\", class_=\"f4 text-normal mb-1\")[i].get_text().strip())\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jason Quense (jquense)',\n",
       " 'Anurag Hazra (anuraghazra)',\n",
       " 'Gleb Bahmutov (bahmutov)',\n",
       " 'Rick Bergfalk (rickbergfalk)',\n",
       " 'Dan Field (dnfield)',\n",
       " 'Sébastien Eustace (sdispater)',\n",
       " 'Sebastián Ramírez (tiangolo)',\n",
       " 'Mike Penz (mikepenz)',\n",
       " '卡色 (cipchk)',\n",
       " 'Jeff Sagal (sagalbot)',\n",
       " 'Sascha Grunert (saschagrunert)',\n",
       " 'Brian Vaughn (bvaughn)',\n",
       " 'Adam Johnson (adamchainz)',\n",
       " 'Brian Douglas (bdougie)',\n",
       " 'Ashley Jeffs (Jeffail)',\n",
       " 'Michael Waskom (mwaskom)',\n",
       " 'Rob Garrison (Mottie)',\n",
       " 'Stephen Celis (stephencelis)',\n",
       " 'Ariel Mashraki (a8m)',\n",
       " 'Joël Galeran (Jolg42)',\n",
       " 'Peter Pistorius (peterp)',\n",
       " 'Philip Walton (philipwalton)',\n",
       " 'Satyajit Sahoo (satya164)',\n",
       " 'Leo Di Donato (leodido)',\n",
       " 'Mr.doob (mrdoob)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developers = [i + \" (\" + j + \")\" for i, j in zip(names, users)] \n",
    "developers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "github1 = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EasyOCR'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repo\n",
    "repos = re.findall(\"\\s\\w+\", github1.find_all(\"h1\", class_=\"h3 lh-condensed\")[1].get_text().strip())[0][1:]\n",
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hackingtool', 'EasyOCR', 'torchsde', 'Complex', 'DeepFaceLab', 'nlp', 'azure', 'mmediting', 'fastapi', 'hit', 'models', 'darts', 'mmdetection3d', 'bbo_challenge_starter_kit', 'modmail', 'sanitizers', 'PayloadsAllTheThings', 'ParamSpider', 'pytorch', 'discord', 'info', 'incubator', 'anchore', 'anomaly', 'airflow']\n"
     ]
    }
   ],
   "source": [
    "repositories = []\n",
    "for i in range(len(github1.find_all(\"h1\", class_=\"h3 lh-condensed\"))):\n",
    "    repositories.append(re.findall(\"\\s\\w+\", github1.find_all(\"h1\", class_=\"h3 lh-condensed\")[i].get_text().strip())[0][1:])\n",
    "\n",
    "print(repositories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "disney = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"http:\"+disney.find_all(\"img\")[2][\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Newman_Laugh-O-Gram_%281921%29.webm/220px-seek%3D2-Newman_Laugh-O-Gram_%281921%29.webm.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/170px-Disney_Display_Case.JPG',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/4/44/The_Walt_Disney_Company_Logo.svg/120px-The_Walt_Disney_Company_Logo.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/29px-P_vip.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/30px-Video-x-generic.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/30px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/30px-Blank_television_set.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/22px-Commons-logo.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/25px-Wikiquote-logo.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/30px-Wikidata-logo.svg.png',\n",
       " 'http://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'http://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " 'http:/static/images/wikimedia-button.png',\n",
       " 'http:/static/images/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney_pics = []\n",
    "for i in range(len(disney.find_all(\"img\"))):\n",
    "    disney_pics.append(\"http:\"+disney.find_all(\"img\")[i][\"src\"])\n",
    "disney_pics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "wiki_python = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = wiki_python.find_all(\"a\")[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Snakes'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a id=\"top\"></a>,\n",
       " <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>,\n",
       " <a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>,\n",
       " <a class=\"extiw\" href=\"https://en.wiktionary.org/wiki/Python\" title=\"wiktionary:Python\">Python</a>,\n",
       " <a class=\"extiw\" href=\"https://en.wiktionary.org/wiki/python\" title=\"wiktionary:python\">python</a>,\n",
       " <a href=\"#Snakes\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Snakes</span></a>,\n",
       " <a href=\"#Ancient_Greece\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Ancient Greece</span></a>,\n",
       " <a href=\"#Media_and_entertainment\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Media and entertainment</span></a>,\n",
       " <a href=\"#Computing\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Computing</span></a>,\n",
       " <a href=\"#Engineering\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Engineering</span></a>,\n",
       " <a href=\"#Roller_coasters\"><span class=\"tocnumber\">5.1</span> <span class=\"toctext\">Roller coasters</span></a>,\n",
       " <a href=\"#Vehicles\"><span class=\"tocnumber\">5.2</span> <span class=\"toctext\">Vehicles</span></a>,\n",
       " <a href=\"#Weaponry\"><span class=\"tocnumber\">5.3</span> <span class=\"toctext\">Weaponry</span></a>,\n",
       " <a href=\"#People\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">People</span></a>,\n",
       " <a href=\"#Other_uses\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Other uses</span></a>,\n",
       " <a href=\"#See_also\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">See also</span></a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=1\" title=\"Edit section: Snakes\">edit</a>,\n",
       " <a href=\"/wiki/Pythonidae\" title=\"Pythonidae\">Pythonidae</a>,\n",
       " <a href=\"/wiki/Python_(genus)\" title=\"Python (genus)\"><i>Python</i> (genus)</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=2\" title=\"Edit section: Ancient Greece\">edit</a>,\n",
       " <a href=\"/wiki/Python_(mythology)\" title=\"Python (mythology)\">Python (mythology)</a>,\n",
       " <a href=\"/wiki/Python_of_Aenus\" title=\"Python of Aenus\">Python of Aenus</a>,\n",
       " <a href=\"/wiki/Python_(painter)\" title=\"Python (painter)\">Python (painter)</a>,\n",
       " <a href=\"/wiki/Python_of_Byzantium\" title=\"Python of Byzantium\">Python of Byzantium</a>,\n",
       " <a href=\"/wiki/Python_of_Catana\" title=\"Python of Catana\">Python of Catana</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=3\" title=\"Edit section: Media and entertainment\">edit</a>,\n",
       " <a href=\"/wiki/Python_(film)\" title=\"Python (film)\"><i>Python</i> (film)</a>,\n",
       " <a href=\"/wiki/Pythons_2\" title=\"Pythons 2\">Pythons 2</a>,\n",
       " <a href=\"/wiki/Monty_Python\" title=\"Monty Python\">Monty Python</a>,\n",
       " <a href=\"/wiki/Python_(Monty)_Pictures\" title=\"Python (Monty) Pictures\">Python (Monty) Pictures</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=4\" title=\"Edit section: Computing\">edit</a>,\n",
       " <a href=\"/wiki/Python_(programming_language)\" title=\"Python (programming language)\">Python (programming language)</a>,\n",
       " <a href=\"/wiki/CPython\" title=\"CPython\">CPython</a>,\n",
       " <a href=\"/wiki/CMU_Common_Lisp\" title=\"CMU Common Lisp\">CMU Common Lisp</a>,\n",
       " <a href=\"/wiki/PERQ#PERQ_3\" title=\"PERQ\">PERQ 3</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=5\" title=\"Edit section: Engineering\">edit</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=6\" title=\"Edit section: Roller coasters\">edit</a>,\n",
       " <a href=\"/wiki/Python_(Busch_Gardens_Tampa_Bay)\" title=\"Python (Busch Gardens Tampa Bay)\">Python (Busch Gardens Tampa Bay)</a>,\n",
       " <a href=\"/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)\" title=\"Python (Coney Island, Cincinnati, Ohio)\">Python (Coney Island, Cincinnati, Ohio)</a>,\n",
       " <a href=\"/wiki/Python_(Efteling)\" title=\"Python (Efteling)\">Python (Efteling)</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=7\" title=\"Edit section: Vehicles\">edit</a>,\n",
       " <a href=\"/wiki/Python_(automobile_maker)\" title=\"Python (automobile maker)\">Python (automobile maker)</a>,\n",
       " <a href=\"/wiki/Python_(Ford_prototype)\" title=\"Python (Ford prototype)\">Python (Ford prototype)</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=8\" title=\"Edit section: Weaponry\">edit</a>,\n",
       " <a href=\"/wiki/Colt_Python\" title=\"Colt Python\">Colt Python</a>,\n",
       " <a href=\"/wiki/Python_(missile)\" title=\"Python (missile)\">Python (missile)</a>,\n",
       " <a href=\"/wiki/Python_(nuclear_primary)\" title=\"Python (nuclear primary)\">Python (nuclear primary)</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=9\" title=\"Edit section: People\">edit</a>,\n",
       " <a href=\"/wiki/Python_Anghelo\" title=\"Python Anghelo\">Python Anghelo</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=10\" title=\"Edit section: Other uses\">edit</a>,\n",
       " <a href=\"/wiki/PYTHON\" title=\"PYTHON\">PYTHON</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=edit&amp;section=11\" title=\"Edit section: See also\">edit</a>,\n",
       " <a href=\"/wiki/Cython\" title=\"Cython\">Cython</a>,\n",
       " <a href=\"/wiki/Pyton\" title=\"Pyton\">Pyton</a>,\n",
       " <a class=\"image\" href=\"/wiki/File:Disambig_gray.svg\"><img alt=\"Disambiguation icon\" data-file-height=\"168\" data-file-width=\"220\" decoding=\"async\" height=\"23\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/5/5f/Disambig_gray.svg/30px-Disambig_gray.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/5/5f/Disambig_gray.svg/45px-Disambig_gray.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/5/5f/Disambig_gray.svg/60px-Disambig_gray.svg.png 2x\" width=\"30\"/></a>,\n",
       " <a href=\"/wiki/Help:Disambiguation\" title=\"Help:Disambiguation\">disambiguation</a>,\n",
       " <a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&amp;namespace=0\">internal link</a>,\n",
       " <a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Python&amp;oldid=963092579\">https://en.wikipedia.org/w/index.php?title=Python&amp;oldid=963092579</a>,\n",
       " <a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>,\n",
       " <a href=\"/wiki/Category:Disambiguation_pages\" title=\"Category:Disambiguation pages\">Disambiguation pages</a>,\n",
       " <a href=\"/wiki/Category:Disambiguation_pages_with_short_descriptions\" title=\"Category:Disambiguation pages with short descriptions\">Disambiguation pages with short descriptions</a>,\n",
       " <a href=\"/wiki/Category:All_article_disambiguation_pages\" title=\"Category:All article disambiguation pages\">All article disambiguation pages</a>,\n",
       " <a href=\"/wiki/Category:All_disambiguation_pages\" title=\"Category:All disambiguation pages\">All disambiguation pages</a>,\n",
       " <a href=\"/wiki/Category:Animal_common_name_disambiguation_pages\" title=\"Category:Animal common name disambiguation pages\">Animal common name disambiguation pages</a>,\n",
       " <a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\">Talk</a>,\n",
       " <a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\">Contributions</a>,\n",
       " <a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Python\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\">Create account</a>,\n",
       " <a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Python\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\">Log in</a>,\n",
       " <a accesskey=\"c\" href=\"/wiki/Python\" title=\"View the content page [c]\">Article</a>,\n",
       " <a accesskey=\"t\" href=\"/wiki/Talk:Python\" rel=\"discussion\" title=\"Discuss improvements to the content page [t]\">Talk</a>,\n",
       " <a href=\"/wiki/Python\">Read</a>,\n",
       " <a accesskey=\"e\" href=\"/w/index.php?title=Python&amp;action=edit\" title=\"Edit this page [e]\">Edit</a>,\n",
       " <a accesskey=\"h\" href=\"/w/index.php?title=Python&amp;action=history\" title=\"Past revisions of this page [h]\">View history</a>,\n",
       " <a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a>,\n",
       " <a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\">Main page</a>,\n",
       " <a href=\"/wiki/Wikipedia:Contents\" title=\"Guides to browsing Wikipedia\">Contents</a>,\n",
       " <a href=\"/wiki/Portal:Current_events\" title=\"Find background information on current events\">Current events</a>,\n",
       " <a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Visit a randomly selected article [x]\">Random article</a>,\n",
       " <a href=\"/wiki/Wikipedia:About\" title=\"Learn about Wikipedia and how it works\">About Wikipedia</a>,\n",
       " <a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\">Contact us</a>,\n",
       " <a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us by donating to the Wikimedia Foundation\">Donate</a>,\n",
       " <a href=\"//shop.wikimedia.org\" title=\"Visit the Wikipedia store\">Wikipedia store</a>,\n",
       " <a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\">Help</a>,\n",
       " <a href=\"/wiki/Wikipedia:Community_portal\" title=\"About the project, what you can do, where to find things\">Community portal</a>,\n",
       " <a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes to Wikipedia [r]\">Recent changes</a>,\n",
       " <a href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Add images or other media for use on Wikipedia\">Upload file</a>,\n",
       " <a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/Python\" title=\"List of all English Wikipedia pages containing links to this page [j]\">What links here</a>,\n",
       " <a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/Python\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\">Related changes</a>,\n",
       " <a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\">Upload file</a>,\n",
       " <a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\">Special pages</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;oldid=963092579\" title=\"Permanent link to this revision of this page\">Permanent link</a>,\n",
       " <a href=\"/w/index.php?title=Python&amp;action=info\" title=\"More information about this page\">Page information</a>,\n",
       " <a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q747452\" title=\"Structured data on this page hosted by Wikidata [g]\">Wikidata item</a>,\n",
       " <a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Python&amp;id=963092579&amp;wpFormIdentifier=titleform\" title=\"Information on how to cite this page\">Cite this page</a>,\n",
       " <a href=\"https://commons.wikimedia.org/wiki/Category:Python\" hreflang=\"en\">Wikimedia Commons</a>,\n",
       " <a href=\"/w/index.php?title=Special:ElectronPdf&amp;page=Python&amp;action=show-download-screen\" title=\"Download this page as a PDF file\">Download as PDF</a>,\n",
       " <a accesskey=\"p\" href=\"/w/index.php?title=Python&amp;printable=yes\" title=\"Printable version of this page [p]\">Printable version</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://af.wikipedia.org/wiki/Python\" hreflang=\"af\" lang=\"af\" title=\"Python – Afrikaans\">Afrikaans</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://als.wikipedia.org/wiki/Python\" hreflang=\"gsw\" lang=\"gsw\" title=\"Python – Alemannisch\">Alemannisch</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86\" hreflang=\"ar\" lang=\"ar\" title=\"بايثون – Arabic\">العربية</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://az.wikipedia.org/wiki/Python\" hreflang=\"az\" lang=\"az\" title=\"Python – Azerbaijani\">Azərbaycanca</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)\" hreflang=\"bn\" lang=\"bn\" title=\"পাইথন (দ্ব্যর্থতা নিরসন) – Bangla\">বাংলা</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://be.wikipedia.org/wiki/Python\" hreflang=\"be\" lang=\"be\" title=\"Python – Belarusian\">Беларуская</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)\" hreflang=\"bg\" lang=\"bg\" title=\"Питон (пояснение) – Bulgarian\">Български</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)\" hreflang=\"cs\" lang=\"cs\" title=\"Python (rozcestník) – Czech\">Čeština</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://da.wikipedia.org/wiki/Python\" hreflang=\"da\" lang=\"da\" title=\"Python – Danish\">Dansk</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://de.wikipedia.org/wiki/Python\" hreflang=\"de\" lang=\"de\" title=\"Python – German\">Deutsch</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://eo.wikipedia.org/wiki/Pitono_(apartigilo)\" hreflang=\"eo\" lang=\"eo\" title=\"Pitono (apartigilo) – Esperanto\">Esperanto</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://eu.wikipedia.org/wiki/Python_(argipena)\" hreflang=\"eu\" lang=\"eu\" title=\"Python (argipena) – Basque\">Euskara</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86\" hreflang=\"fa\" lang=\"fa\" title=\"پایتون – Persian\">فارسی</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://fr.wikipedia.org/wiki/Python\" hreflang=\"fr\" lang=\"fr\" title=\"Python – French\">Français</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0\" hreflang=\"ko\" lang=\"ko\" title=\"파이선 – Korean\">한국어</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://hr.wikipedia.org/wiki/Python_(razdvojba)\" hreflang=\"hr\" lang=\"hr\" title=\"Python (razdvojba) – Croatian\">Hrvatski</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://io.wikipedia.org/wiki/Pitono\" hreflang=\"io\" lang=\"io\" title=\"Pitono – Ido\">Ido</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://id.wikipedia.org/wiki/Python\" hreflang=\"id\" lang=\"id\" title=\"Python – Indonesian\">Bahasa Indonesia</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ia.wikipedia.org/wiki/Python_(disambiguation)\" hreflang=\"ia\" lang=\"ia\" title=\"Python (disambiguation) – Interlingua\">Interlingua</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)\" hreflang=\"is\" lang=\"is\" title=\"Python (aðgreining) – Icelandic\">Íslenska</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://it.wikipedia.org/wiki/Python_(disambigua)\" hreflang=\"it\" lang=\"it\" title=\"Python (disambigua) – Italian\">Italiano</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F\" hreflang=\"he\" lang=\"he\" title=\"פיתון – Hebrew\">עברית</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)\" hreflang=\"ka\" lang=\"ka\" title=\"პითონი (მრავალმნიშვნელოვანი) – Georgian\">ქართული</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://kg.wikipedia.org/wiki/Mboma_(nyoka)\" hreflang=\"kg\" lang=\"kg\" title=\"Mboma (nyoka) – Kongo\">Kongo</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://la.wikipedia.org/wiki/Python_(discretiva)\" hreflang=\"la\" lang=\"la\" title=\"Python (discretiva) – Latin\">Latina</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://lb.wikipedia.org/wiki/Python\" hreflang=\"lb\" lang=\"lb\" title=\"Python – Luxembourgish\">Lëtzebuergesch</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)\" hreflang=\"hu\" lang=\"hu\" title=\"Python (egyértelműsítő lap) – Hungarian\">Magyar</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)\" hreflang=\"mr\" lang=\"mr\" title=\"पायथॉन (आज्ञावली भाषा) – Marathi\">मराठी</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://nl.wikipedia.org/wiki/Python\" hreflang=\"nl\" lang=\"nl\" title=\"Python – Dutch\">Nederlands</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3\" hreflang=\"ja\" lang=\"ja\" title=\"パイソン – Japanese\">日本語</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://no.wikipedia.org/wiki/Pyton\" hreflang=\"nb\" lang=\"nb\" title=\"Pyton – Norwegian Bokmål\">Norsk bokmål</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://pl.wikipedia.org/wiki/Pyton\" hreflang=\"pl\" lang=\"pl\" title=\"Pyton – Polish\">Polski</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)\" hreflang=\"pt\" lang=\"pt\" title=\"Python (desambiguação) – Portuguese\">Português</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)\" hreflang=\"ru\" lang=\"ru\" title=\"Python (значения) – Russian\">Русский</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://sk.wikipedia.org/wiki/Python\" hreflang=\"sk\" lang=\"sk\" title=\"Python – Slovak\">Slovenčina</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)\" hreflang=\"sr\" lang=\"sr\" title=\"Питон (вишезначна одредница) – Serbian\">Српски / srpski</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://sh.wikipedia.org/wiki/Python\" hreflang=\"sh\" lang=\"sh\" title=\"Python – Serbo-Croatian\">Srpskohrvatski / српскохрватски</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://fi.wikipedia.org/wiki/Python\" hreflang=\"fi\" lang=\"fi\" title=\"Python – Finnish\">Suomi</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://sv.wikipedia.org/wiki/Pyton\" hreflang=\"sv\" lang=\"sv\" title=\"Pyton – Swedish\">Svenska</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99\" hreflang=\"th\" lang=\"th\" title=\"ไพทอน – Thai\">ไทย</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://tr.wikipedia.org/wiki/Python\" hreflang=\"tr\" lang=\"tr\" title=\"Python – Turkish\">Türkçe</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD\" hreflang=\"uk\" lang=\"uk\" title=\"Піфон – Ukrainian\">Українська</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86\" hreflang=\"ur\" lang=\"ur\" title=\"پائیتھون – Urdu\">اردو</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://vi.wikipedia.org/wiki/Python\" hreflang=\"vi\" lang=\"vi\" title=\"Python – Vietnamese\">Tiếng Việt</a>,\n",
       " <a class=\"interlanguage-link-target\" href=\"https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)\" hreflang=\"zh\" lang=\"zh\" title=\"Python (消歧义) – Chinese\">中文</a>,\n",
       " <a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia\" title=\"Edit interlanguage links\">Edit links</a>,\n",
       " <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License</a>,\n",
       " <a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>,\n",
       " <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a>,\n",
       " <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy</a>,\n",
       " <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>,\n",
       " <a class=\"extiw\" href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\" title=\"wmf:Privacy policy\">Privacy policy</a>,\n",
       " <a href=\"/wiki/Wikipedia:About\" title=\"Wikipedia:About\">About Wikipedia</a>,\n",
       " <a href=\"/wiki/Wikipedia:General_disclaimer\" title=\"Wikipedia:General disclaimer\">Disclaimers</a>,\n",
       " <a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a>,\n",
       " <a href=\"https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\">Developers</a>,\n",
       " <a href=\"https://stats.wikimedia.org/#/en.wikipedia.org\">Statistics</a>,\n",
       " <a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a>,\n",
       " <a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=Python&amp;mobileaction=toggle_view_mobile\">Mobile view</a>,\n",
       " <a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" loading=\"lazy\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/></a>,\n",
       " <a href=\"https://www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" loading=\"lazy\" src=\"/static/images/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "for i in range(len(wiki_python.find_all(\"a\"))):\n",
    "    links.append(wiki_python.find_all(\"a\")[i])\n",
    "    \n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of titles that have changed in the United States Code since its last release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "codes = BeautifulSoup(page.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Copyrights ٭'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"-.*$\", codes.find_all(\"div\", class_=\"usctitlechanged\")[4].get_text().strip())[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Domestic Security',\n",
       " 'Agriculture',\n",
       " 'Aliens and Nationality',\n",
       " 'Commerce and Trade',\n",
       " 'Copyrights ٭',\n",
       " 'Customs Duties',\n",
       " 'Foreign Relations and Intercourse',\n",
       " 'Internal Revenue Code',\n",
       " 'Judiciary and Judicial Procedure ٭',\n",
       " \"Veterans' Benefits ٭\",\n",
       " 'The Public Health and Welfare']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = []\n",
    "for i in range(len(codes.find_all(\"div\", class_=\"usctitlechanged\"))):\n",
    "    titles.append(re.findall(r\"-.*$\", codes.find_all(\"div\", class_=\"usctitlechanged\")[i].get_text().strip())[0][2:])\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a Python list with the top ten FBI's Most Wanted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "fbi = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALEJANDRO ROSALES CASTILLO'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi.find_all(\"h3\", class_=\"title\")[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALEJANDRO ROSALES CASTILLO',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN',\n",
       " 'YASER ABDEL SAID',\n",
       " 'ALEXIS FLORES',\n",
       " 'EUGENE PALMER',\n",
       " 'SANTIAGO VILLALBA MEDEROS',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi_wanted = []\n",
    "for i in range(len(fbi.find_all(\"h3\", class_=\"title\"))):\n",
    "    fbi_wanted.append(fbi.find_all(\"h3\", class_=\"title\")[i].get_text().strip())\n",
    "fbi_wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "earthquake = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'earthquake2020-07-12\\xa0\\xa0\\xa007:38:44.832min ago'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date and time\n",
    "earthquake.find_all(\"td\", class_=\"tabev6\")[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-12'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date\n",
    "re.findall(r\"\\d{4}-\\d{2}-\\d{2}\", earthquake.find_all(\"td\", class_=\"tabev6\")[0].get_text())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07:38:44'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time\n",
    "re.findall(r\"\\d{2}:\\d{2}:\\d{2}\", earthquake.find_all(\"td\", class_=\"tabev6\")[0].get_text())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates list\n",
    "dates = []\n",
    "for i in range(len(earthquake.find_all(\"td\", class_=\"tabev6\"))):\n",
    "    dates.append(re.findall(r\"\\d{4}-\\d{2}-\\d{2}\", earthquake.find_all(\"td\", class_=\"tabev6\")[i].get_text())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times list\n",
    "times = []\n",
    "for i in range(len(earthquake.find_all(\"td\", class_=\"tabev6\"))):\n",
    "    times.append(re.findall(r\"\\d{2}:\\d{2}:\\d{2}\", earthquake.find_all(\"td\", class_=\"tabev6\")[i].get_text())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['54.12', '57.07', '36.05', '17.58', '35.63', '0.70', '1.83', '33.63', '19.18', '36.47', '14.19', '5.16', '36.76', '41.79', '45.99', '38.18', '19.36', '38.79', '3.81', '18.19', '19.89', '52.27', '36.45', '16.57', '24.96', '27.95', '21.73', '18.03', '42.61', '39.01', '9.70', '17.95', '10.15', '17.92', '36.45', '8.21', '38.18', '8.32', '12.59', '15.54', '18.09', '22.56', '38.16', '38.47', '21.94', '38.23', '35.55', '35.67', '38.44', '41.12']\n",
      "['161.35', '154.17', '30.27', '94.50', '52.61', '126.94', '128.90', '102.89', '155.44', '9.90', '120.46', '102.44', '98.07', '43.80', '7.85', '117.98', '155.42', '25.32', '97.60', '69.88', '143.95', '169.49', '117.99', '99.31', '122.86', '16.38', '68.66', '101.00', '13.23', '27.86', '159.93', '67.00', '83.20', '66.91', '71.02', '82.80', '117.74', '82.80', '89.55', '96.30', '178.28', '69.45', '117.97', '39.25', '68.75', '108.96', '52.43', '117.51', '39.24', '75.26']\n"
     ]
    }
   ],
   "source": [
    "# latitude and longitudes\n",
    "earthquake.find_all(\"td\", class_=\"tabev1\")[1].get_text().strip()\n",
    "\n",
    "latitudes_longitudes = []\n",
    "\n",
    "for i in range(len(earthquake.find_all(\"td\", class_=\"tabev1\"))):\n",
    "    latitudes_longitudes.append(earthquake.find_all(\"td\", class_=\"tabev1\")[i].get_text().strip())\n",
    "\n",
    "latitudes = latitudes_longitudes[::2] # latitudes are the odd index positions\n",
    "\n",
    "longitudes = latitudes_longitudes[1::2] # longitudes are the even index positions\n",
    "\n",
    "print(latitudes)\n",
    "print(longitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region\n",
    "earthquake.find_all(\"td\", class_=\"tb_region\")[1].get_text().strip()\n",
    "\n",
    "regions = []\n",
    "for i in range(len(earthquake.find_all(\"td\", class_=\"tb_region\"))):\n",
    "    regions.append(earthquake.find_all(\"td\", class_=\"tb_region\")[i].get_text().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:38:44</td>\n",
       "      <td>54.12</td>\n",
       "      <td>161.35</td>\n",
       "      <td>ALASKA PENINSULA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:26:37</td>\n",
       "      <td>57.07</td>\n",
       "      <td>154.17</td>\n",
       "      <td>KODIAK ISLAND REGION, ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:25:13</td>\n",
       "      <td>36.05</td>\n",
       "      <td>30.27</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:21:56</td>\n",
       "      <td>17.58</td>\n",
       "      <td>94.50</td>\n",
       "      <td>VERACRUZ, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:19:55</td>\n",
       "      <td>35.63</td>\n",
       "      <td>52.61</td>\n",
       "      <td>NORTHERN IRAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:13:05</td>\n",
       "      <td>0.70</td>\n",
       "      <td>126.94</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:06:40</td>\n",
       "      <td>1.83</td>\n",
       "      <td>128.90</td>\n",
       "      <td>KEPULAUAN OBI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>07:03:28</td>\n",
       "      <td>33.63</td>\n",
       "      <td>102.89</td>\n",
       "      <td>QINGHAI-SICHUAN BORDER RG, CHINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>06:57:31</td>\n",
       "      <td>19.18</td>\n",
       "      <td>155.44</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>06:48:27</td>\n",
       "      <td>36.47</td>\n",
       "      <td>9.90</td>\n",
       "      <td>WEST OF GIBRALTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>06:45:18</td>\n",
       "      <td>14.19</td>\n",
       "      <td>120.46</td>\n",
       "      <td>LUZON, PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>06:27:09</td>\n",
       "      <td>5.16</td>\n",
       "      <td>102.44</td>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>06:24:43</td>\n",
       "      <td>36.76</td>\n",
       "      <td>98.07</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>05:54:53</td>\n",
       "      <td>41.79</td>\n",
       "      <td>43.80</td>\n",
       "      <td>GEORGIA (SAK'ART'VELO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>05:45:51</td>\n",
       "      <td>45.99</td>\n",
       "      <td>7.85</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>05:31:26</td>\n",
       "      <td>38.18</td>\n",
       "      <td>117.98</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>05:23:37</td>\n",
       "      <td>19.36</td>\n",
       "      <td>155.42</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>05:06:38</td>\n",
       "      <td>38.79</td>\n",
       "      <td>25.32</td>\n",
       "      <td>AEGEAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:52:59</td>\n",
       "      <td>3.81</td>\n",
       "      <td>97.60</td>\n",
       "      <td>NORTHERN SUMATRA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:48:23</td>\n",
       "      <td>18.19</td>\n",
       "      <td>69.88</td>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:29:27</td>\n",
       "      <td>19.89</td>\n",
       "      <td>143.95</td>\n",
       "      <td>QUEENSLAND, AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:20:24</td>\n",
       "      <td>52.27</td>\n",
       "      <td>169.49</td>\n",
       "      <td>FOX ISLANDS, ALEUTIAN ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:09:56</td>\n",
       "      <td>36.45</td>\n",
       "      <td>117.99</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:07:33</td>\n",
       "      <td>16.57</td>\n",
       "      <td>99.31</td>\n",
       "      <td>OFFSHORE GUERRERO, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>04:06:07</td>\n",
       "      <td>24.96</td>\n",
       "      <td>122.86</td>\n",
       "      <td>TAIWAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:57:17</td>\n",
       "      <td>27.95</td>\n",
       "      <td>16.38</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:43:22</td>\n",
       "      <td>21.73</td>\n",
       "      <td>68.66</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:33:22</td>\n",
       "      <td>18.03</td>\n",
       "      <td>101.00</td>\n",
       "      <td>GUERRERO, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:23:20</td>\n",
       "      <td>42.61</td>\n",
       "      <td>13.23</td>\n",
       "      <td>CENTRAL ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:19:38</td>\n",
       "      <td>39.01</td>\n",
       "      <td>27.86</td>\n",
       "      <td>WESTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:04:16</td>\n",
       "      <td>9.70</td>\n",
       "      <td>159.93</td>\n",
       "      <td>SOLOMON ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>03:00:37</td>\n",
       "      <td>17.95</td>\n",
       "      <td>67.00</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:57:30</td>\n",
       "      <td>10.15</td>\n",
       "      <td>83.20</td>\n",
       "      <td>COSTA RICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:50:28</td>\n",
       "      <td>17.92</td>\n",
       "      <td>66.91</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:49:27</td>\n",
       "      <td>36.45</td>\n",
       "      <td>71.02</td>\n",
       "      <td>HINDU KUSH REGION, AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:42:30</td>\n",
       "      <td>8.21</td>\n",
       "      <td>82.80</td>\n",
       "      <td>PANAMA-COSTA RICA BORDER REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:23:17</td>\n",
       "      <td>38.18</td>\n",
       "      <td>117.74</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:14:30</td>\n",
       "      <td>8.32</td>\n",
       "      <td>82.80</td>\n",
       "      <td>PANAMA-COSTA RICA BORDER REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>02:11:20</td>\n",
       "      <td>12.59</td>\n",
       "      <td>89.55</td>\n",
       "      <td>OFFSHORE EL SALVADOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>01:43:49</td>\n",
       "      <td>15.54</td>\n",
       "      <td>96.30</td>\n",
       "      <td>OFFSHORE OAXACA, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>01:43:10</td>\n",
       "      <td>18.09</td>\n",
       "      <td>178.28</td>\n",
       "      <td>FIJI REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>01:29:28</td>\n",
       "      <td>22.56</td>\n",
       "      <td>69.45</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>01:27:00</td>\n",
       "      <td>38.16</td>\n",
       "      <td>117.97</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:55:15</td>\n",
       "      <td>38.47</td>\n",
       "      <td>39.25</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:54:13</td>\n",
       "      <td>21.94</td>\n",
       "      <td>68.75</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:50:36</td>\n",
       "      <td>38.23</td>\n",
       "      <td>108.96</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:45:36</td>\n",
       "      <td>35.55</td>\n",
       "      <td>52.43</td>\n",
       "      <td>NORTHERN IRAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:44:26</td>\n",
       "      <td>35.67</td>\n",
       "      <td>117.51</td>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:36:05</td>\n",
       "      <td>38.44</td>\n",
       "      <td>39.24</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-07-12</td>\n",
       "      <td>00:28:48</td>\n",
       "      <td>41.12</td>\n",
       "      <td>75.26</td>\n",
       "      <td>KYRGYZSTAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      time latitude longitude                            region\n",
       "0   2020-07-12  07:38:44    54.12    161.35                  ALASKA PENINSULA\n",
       "1   2020-07-12  07:26:37    57.07    154.17      KODIAK ISLAND REGION, ALASKA\n",
       "2   2020-07-12  07:25:13    36.05     30.27                    WESTERN TURKEY\n",
       "3   2020-07-12  07:21:56    17.58     94.50                  VERACRUZ, MEXICO\n",
       "4   2020-07-12  07:19:55    35.63     52.61                     NORTHERN IRAN\n",
       "5   2020-07-12  07:13:05     0.70    126.94                       MOLUCCA SEA\n",
       "6   2020-07-12  07:06:40     1.83    128.90          KEPULAUAN OBI, INDONESIA\n",
       "7   2020-07-12  07:03:28    33.63    102.89  QINGHAI-SICHUAN BORDER RG, CHINA\n",
       "8   2020-07-12  06:57:31    19.18    155.44          ISLAND OF HAWAII, HAWAII\n",
       "9   2020-07-12  06:48:27    36.47      9.90                 WEST OF GIBRALTAR\n",
       "10  2020-07-12  06:45:18    14.19    120.46                LUZON, PHILIPPINES\n",
       "11  2020-07-12  06:27:09     5.16    102.44       SOUTHERN SUMATRA, INDONESIA\n",
       "12  2020-07-12  06:24:43    36.76     98.07                          OKLAHOMA\n",
       "13  2020-07-12  05:54:53    41.79     43.80            GEORGIA (SAK'ART'VELO)\n",
       "14  2020-07-12  05:45:51    45.99      7.85                       SWITZERLAND\n",
       "15  2020-07-12  05:31:26    38.18    117.98                            NEVADA\n",
       "16  2020-07-12  05:23:37    19.36    155.42          ISLAND OF HAWAII, HAWAII\n",
       "17  2020-07-12  05:06:38    38.79     25.32                        AEGEAN SEA\n",
       "18  2020-07-12  04:52:59     3.81     97.60       NORTHERN SUMATRA, INDONESIA\n",
       "19  2020-07-12  04:48:23    18.19     69.88                   TARAPACA, CHILE\n",
       "20  2020-07-12  04:29:27    19.89    143.95             QUEENSLAND, AUSTRALIA\n",
       "21  2020-07-12  04:20:24    52.27    169.49     FOX ISLANDS, ALEUTIAN ISLANDS\n",
       "22  2020-07-12  04:09:56    36.45    117.99                CENTRAL CALIFORNIA\n",
       "23  2020-07-12  04:07:33    16.57     99.31         OFFSHORE GUERRERO, MEXICO\n",
       "24  2020-07-12  04:06:07    24.96    122.86                     TAIWAN REGION\n",
       "25  2020-07-12  03:57:17    27.95     16.38      CANARY ISLANDS, SPAIN REGION\n",
       "26  2020-07-12  03:43:22    21.73     68.66                ANTOFAGASTA, CHILE\n",
       "27  2020-07-12  03:33:22    18.03    101.00                  GUERRERO, MEXICO\n",
       "28  2020-07-12  03:23:20    42.61     13.23                     CENTRAL ITALY\n",
       "29  2020-07-12  03:19:38    39.01     27.86                    WESTERN TURKEY\n",
       "30  2020-07-12  03:04:16     9.70    159.93                   SOLOMON ISLANDS\n",
       "31  2020-07-12  03:00:37    17.95     67.00                PUERTO RICO REGION\n",
       "32  2020-07-12  02:57:30    10.15     83.20                        COSTA RICA\n",
       "33  2020-07-12  02:50:28    17.92     66.91                PUERTO RICO REGION\n",
       "34  2020-07-12  02:49:27    36.45     71.02    HINDU KUSH REGION, AFGHANISTAN\n",
       "35  2020-07-12  02:42:30     8.21     82.80   PANAMA-COSTA RICA BORDER REGION\n",
       "36  2020-07-12  02:23:17    38.18    117.74                            NEVADA\n",
       "37  2020-07-12  02:14:30     8.32     82.80   PANAMA-COSTA RICA BORDER REGION\n",
       "38  2020-07-12  02:11:20    12.59     89.55              OFFSHORE EL SALVADOR\n",
       "39  2020-07-12  01:43:49    15.54     96.30           OFFSHORE OAXACA, MEXICO\n",
       "40  2020-07-12  01:43:10    18.09    178.28                       FIJI REGION\n",
       "41  2020-07-12  01:29:28    22.56     69.45                ANTOFAGASTA, CHILE\n",
       "42  2020-07-12  01:27:00    38.16    117.97                            NEVADA\n",
       "43  2020-07-12  00:55:15    38.47     39.25                    EASTERN TURKEY\n",
       "44  2020-07-12  00:54:13    21.94     68.75                ANTOFAGASTA, CHILE\n",
       "45  2020-07-12  00:50:36    38.23    108.96                          COLORADO\n",
       "46  2020-07-12  00:45:36    35.55     52.43                     NORTHERN IRAN\n",
       "47  2020-07-12  00:44:26    35.67    117.51               SOUTHERN CALIFORNIA\n",
       "48  2020-07-12  00:36:05    38.44     39.24                    EASTERN TURKEY\n",
       "49  2020-07-12  00:28:48    41.12     75.26                        KYRGYZSTAN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes_df = pd.DataFrame({\"date\": dates,\n",
    "                              \"time\": times,\n",
    "                              \"latitude\": latitudes,\n",
    "                              \"longitude\": longitudes,\n",
    "                              \"region\": regions})\n",
    "earthquakes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<strong>English</strong>, <strong>日本語</strong>, <strong>Español</strong>, <strong>Deutsch</strong>, <strong>Русский</strong>, <strong>Français</strong>, <strong>Italiano</strong>, <strong>中文</strong>, <strong>Português</strong>, <strong>Polski</strong>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['English',\n",
       " '日本語',\n",
       " 'Español',\n",
       " 'Deutsch',\n",
       " 'Русский',\n",
       " 'Français',\n",
       " 'Italiano',\n",
       " '中文',\n",
       " 'Português',\n",
       " 'Polski']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# languages\n",
    "print(soup.select(\"strong\")[1:-1]) # delete first and last item of list as they are not languages\n",
    "len(soup.select(\"strong\")[1:-1]) # find length of list for foor loop\n",
    "\n",
    "#languages list\n",
    "languages = []\n",
    "for i in range(1,11):\n",
    "    languages.append(soup.select(\"strong\")[i].get_text())\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bdi dir=\"ltr\">6 116 000+</bdi>\n",
      "['6', '116', '000']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6116000',\n",
       " '1215000',\n",
       " '1610000',\n",
       " '2452000',\n",
       " '1641000',\n",
       " '2233000',\n",
       " '1620000',\n",
       " '1127000',\n",
       " '1038000',\n",
       " '1418000']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of articles \n",
    "soup.select(\"bdi\")[0:10] # select only first 10\n",
    "print(soup.select(\"bdi\")[0])\n",
    "print(re.findall(r\"\\d+\", soup.select(\"bdi\")[0].get_text()))\n",
    "\n",
    "\"\".join(re.findall(r\"\\d+\", soup.select(\"bdi\")[0].get_text())) # regex returns list of numbers, so we join them\n",
    "\n",
    "# list of number of articles\n",
    "articles = []\n",
    "for i in range(0,10):\n",
    "    articles.append(\"\".join(re.findall(r\"\\d+\", soup.select(\"bdi\")[i].get_text())))\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English: 6116000',\n",
       " '日本語: 1215000',\n",
       " 'Español: 1610000',\n",
       " 'Deutsch: 2452000',\n",
       " 'Русский: 1641000',\n",
       " 'Français: 2233000',\n",
       " 'Italiano: 1620000',\n",
       " '中文: 1127000',\n",
       " 'Português: 1038000',\n",
       " 'Polski: 1418000']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = [i +\": \"+j for i,j in zip(languages, articles)]\n",
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets\n",
    "soup.select(\".govuk-link\")[3:] # first result we want is at index 3\n",
    "soup.select(\".govuk-link\")[3].get_text()\n",
    "len(soup.select(\".govuk-link\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets list\n",
    "datasets = []\n",
    "for i in range(3,15):\n",
    "    datasets.append(soup.select(\".govuk-link\")[i].get_text())\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the top 10 languages by number of native speakers stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [soup.select(\"tbody tr td a\")[i].get_text() for i in range(10)][::3] # first list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = [soup.select(\"tbody tr td a\")[i].get_text() for i in range(14,27)][::3] # second list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = [soup.select(\"tbody tr td a\")[30].get_text()] # third list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandarin Chinese',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'Bengali',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Western Punjabi',\n",
       " 'Marathi']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = list1 + list2 + list3\n",
    "languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city: barcelona\n"
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peter Pistorius'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github.find_all(\"h1\", class_=\"h3 lh-condensed\")[20].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
