{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "devs = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(select,dict_value=0):\n",
    "    text=[]\n",
    "    for tag in select:\n",
    "        if dict_value==0:\n",
    "            text.append(tag.get_text().strip())\n",
    "        else:\n",
    "            text.append(tag[dict_value])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David Teather (davidteather)',\n",
       " 'Héctor Ramón (hecrj)',\n",
       " 'Alon Zakai (kripken)',\n",
       " 'Mladen Macanović (stsrki)',\n",
       " 'Jirka Borovec (Borda)',\n",
       " 'Calin Crisan (ccrisan)',\n",
       " 'Anurag Hazra (anuraghazra)',\n",
       " 'Thomas Lovén (thomasloven)',\n",
       " 'Joe Block (unixorn)',\n",
       " 'Michael Staib (michaelstaib)',\n",
       " 'Tom Moor (tommoor)',\n",
       " 'Aditya Oke (oke-aditya)',\n",
       " 'Jethro Kuan (jethrokuan)',\n",
       " 'An Tao (an-tao)',\n",
       " 'Alex Ellis (alexellis)',\n",
       " 'Arvid Norberg (arvidn)',\n",
       " 'Sorin Sbarnea (ssbarnea)',\n",
       " 'Evan Wallace (evanw)',\n",
       " 'Alex Gaynor (alex)',\n",
       " 'Christian Rotzoll (rootzoll)',\n",
       " 'Stefano Gottardo (CastagnaIT)',\n",
       " 'Gio Lodi (mokagio)',\n",
       " 'Tim Holy (timholy)',\n",
       " 'Gleb Bahmutov (bahmutov)',\n",
       " 'Yoni Goldberg (goldbergyoni)']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "full_name = []\n",
    "full_name=read_text(devs.select(\"div.d-sm-flex.flex-auto > div.col-sm-8.d-md-flex > div:nth-child(1)\"))\n",
    "\n",
    "for i in range(len(full_name)):\n",
    "    full_name[i]=re.sub(r\"\\n\\s*\",\" (\",full_name[i])\n",
    "    if \" \" in full_name[i]:\n",
    "        full_name[i]=full_name[i]+\")\"\n",
    "\n",
    "full_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'\n",
    "\n",
    "response = requests.get(url)\n",
    "repos = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['microsoft / (Bringing-Old-Photos-Back-to-Life)',\n",
       " 'joke2k / (faker)',\n",
       " 'home-assistant / (core)',\n",
       " 'Asabeneh / (30-Days-Of-Python)',\n",
       " 'PyTorchLightning / (pytorch-lightning)',\n",
       " 'apprenticeharper / (DeDRM_tools)',\n",
       " 'django / (django)',\n",
       " 'matplotlib / (matplotlib)',\n",
       " 'freqtrade / (freqtrade)',\n",
       " 'ankitects / (anki)',\n",
       " 'ageitgey / (face_recognition)',\n",
       " 'Zero-S1 / (xmly_speed)',\n",
       " 'DIGITALCRIMINAL / (OnlyFans)',\n",
       " 'public-apis / (public-apis)',\n",
       " 'ct-Open-Source / (tuya-convert)',\n",
       " 'davidteather / (TikTok-Api)',\n",
       " 'lutris / (lutris)',\n",
       " 'EntySec / (ghost)',\n",
       " 'quentinhardy / (pytmipe)',\n",
       " 'Z4nzu / (hackingtool)',\n",
       " 'kernc / (backtesting.py)',\n",
       " 'The-Art-of-Hacking / (h4cker)',\n",
       " 'drduh / (macOS-Security-and-Privacy-Guide)',\n",
       " 'spesmilo / (electrum)',\n",
       " 'smicallef / (spiderfoot)']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "full_repos=read_text(repos.select(\"div > div> article > h1 > a\"))\n",
    "\n",
    "for i in range(len(full_repos)):\n",
    "    full_repos[i]=re.sub(r\"\\n\\s*\",\" (\",full_repos[i])\n",
    "    full_repos[i]=full_repos[i]+\")\"\n",
    "full_repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "response = requests.get(url)\n",
    "waltie = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png', '//upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG', '//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Newman_Laugh-O-Gram_%281921%29.webm/220px-seek%3D2-Newman_Laugh-O-Gram_%281921%29.webm.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg', '//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG', '//upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg', '//upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/170px-Disney_Display_Case.JPG', '//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg', '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png', '//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/29px-P_vip.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg', '//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/30px-Video-x-generic.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/30px-Flag_of_Los_Angeles_County%2C_California.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/30px-Blank_television_set.svg.png', '//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png', '//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/22px-Commons-logo.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/25px-Wikiquote-logo.svg.png', '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/30px-Wikidata-logo.svg.png', '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png', '//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1', '/static/images/footer/wikimedia-button.png', '/static/images/footer/poweredby_mediawiki_88x31.png']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#read_text(waltie.find_all(\"img\"),\"src\")\n",
    "text=[]\n",
    "for tag in waltie.find_all(\"img\"):\n",
    "    text.append(tag[\"src\"])\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python'\n",
    "response = requests.get(url)\n",
    "python = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "allLinks = read_text(python.find(id=\"bodyContent\").find_all(\"a\"),\"href\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " '/wiki/Pythons',\n",
       " '/wiki/Python_(genus)',\n",
       " '/w/index.php?title=Python&action=edit&section=1',\n",
       " '/wiki/Python_(programming_language)',\n",
       " '/wiki/CMU_Common_Lisp',\n",
       " '/w/index.php?title=Python&action=edit&section=2',\n",
       " '/wiki/Python_of_Aenus',\n",
       " '/wiki/Python_(painter)',\n",
       " '/wiki/Python_of_Byzantium',\n",
       " '/wiki/Python_of_Catana',\n",
       " '/wiki/Python_Anghelo',\n",
       " '/w/index.php?title=Python&action=edit&section=3',\n",
       " '/wiki/Python_(Efteling)',\n",
       " '/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " '/w/index.php?title=Python&action=edit&section=4',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Python_(Ford_prototype)',\n",
       " '/w/index.php?title=Python&action=edit&section=5',\n",
       " '/wiki/Python_(missile)',\n",
       " '/wiki/Python_(nuclear_primary)',\n",
       " '/wiki/Colt_Python',\n",
       " '/w/index.php?title=Python&action=edit&section=6',\n",
       " '/wiki/PYTHON',\n",
       " '/wiki/Python_(film)',\n",
       " '/wiki/Python_(mythology)',\n",
       " '/wiki/Monty_Python',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/w/index.php?title=Python&action=edit&section=7',\n",
       " '/wiki/Cython',\n",
       " '/wiki/Pyton',\n",
       " '/wiki/Pithon',\n",
       " '/wiki/File:Disambig_gray.svg',\n",
       " '/wiki/Help:Disambiguation',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=987482924',\n",
       " '/wiki/Help:Category',\n",
       " '/wiki/Category:Disambiguation_pages',\n",
       " '/wiki/Category:Human_name_disambiguation_pages',\n",
       " '/wiki/Category:Disambiguation_pages_with_given-name-holder_lists',\n",
       " '/wiki/Category:Disambiguation_pages_with_short_descriptions',\n",
       " '/wiki/Category:Short_description_is_different_from_Wikidata',\n",
       " '/wiki/Category:All_article_disambiguation_pages',\n",
       " '/wiki/Category:All_disambiguation_pages',\n",
       " '/wiki/Category:Animal_common_name_disambiguation_pages']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLinks_clean=[]\n",
    "\n",
    "for i in allLinks:\n",
    "    if '#' not in i:\n",
    "        allLinks_clean.append(i)\n",
    "                 \n",
    "allLinks_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of titles that have changed in the United States Code since its last release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "response = requests.get(url)\n",
    "titles = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 7 - Agriculture',\n",
       " 'Title 11 - Bankruptcy ٭',\n",
       " 'Title 13 - Census ٭',\n",
       " 'Title 14 - Coast Guard ٭',\n",
       " 'Title 15 - Commerce and Trade',\n",
       " 'Title 16 - Conservation',\n",
       " 'Title 21 - Food and Drugs',\n",
       " 'Title 24 - Hospitals and Asylums',\n",
       " 'Title 27 - Intoxicating Liquors',\n",
       " 'Title 32 - National Guard ٭',\n",
       " 'Title 33 - Navigation and Navigable Waters',\n",
       " 'Title 34 - Crime Control and Law Enforcement',\n",
       " 'Title 36 - Patriotic and National Observances, Ceremonies, and Organizations ٭',\n",
       " \"Title 38 - Veterans' Benefits ٭\",\n",
       " 'Title 42 - The Public Health and Welfare',\n",
       " 'Title 45 - Railroads',\n",
       " 'Title 49 - Transportation ٭',\n",
       " 'Title 54 - National Park Service and Related Programs ٭']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "#read_text(titles.find_all(\"div\", {\"class\":\"usctitlechanged\"}))\n",
    "read_text(titles.find_all(\"div\", class_=\"usctitlechanged\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a Python list with the top ten FBI's Most Wanted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "response = requests.get(url)\n",
    "wanted = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALEJANDRO ROSALES CASTILLO',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'EUGENE PALMER',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'YASER ABDEL SAID']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "read_text(wanted.select(\"#query-results-0f737222c5054a81a120bce207b0446a > ul > li\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "response = requests.get(url)\n",
    "geo = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date and Time: \n",
    "geo.select(\"td.tabev6 > b > a\")\n",
    "time=[]\n",
    "i=0\n",
    "for g in geo.select(\"td.tabev6 > b > a\"):\n",
    "    if i<20:\n",
    "        time.append(g.get_text())\n",
    "    i+=1\n",
    "clean_date_time=[]\n",
    "for t in time:\n",
    "    clean_date_time.append(t.split())\n",
    "\n",
    "dates=[]\n",
    "times=[]\n",
    "for t in clean_date_time:\n",
    "    dates.append(t[0])\n",
    "    times.append(t[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#latitude-longitude\n",
    "\n",
    "#Adding numerical values to the list:\n",
    "\n",
    "i=0\n",
    "lat_long=[]\n",
    "latitudes=[]\n",
    "longitudes=[]\n",
    "\n",
    "for g in geo.find_all(\"td\",class_=\"tabev1\"):\n",
    "    if i<40:\n",
    "        lat_long.append(g.get_text())\n",
    "    i+=1\n",
    "    \n",
    "   \n",
    "for i in range(len(lat_long)):\n",
    "    lat_long[i]=re.sub(r\"\\xa0\",\"\",lat_long[i])\n",
    "    if i%2==0:\n",
    "        latitudes.append(lat_long[i])\n",
    "    else:\n",
    "        longitudes.append(lat_long[i])\n",
    "        \n",
    "#adding cardinal symbols to a list\n",
    "\n",
    "i=0\n",
    "cardinals=[]\n",
    "card_lat=[]\n",
    "card_long=[]\n",
    "\n",
    "for g in read_text(geo.find_all(\"td\",class_=\"tabev2\")):\n",
    "    if i<60 and re.match(r\"[NSWE]\", g) is not None:\n",
    "        cardinals.append(g)\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "for i in range(len(cardinals)):\n",
    "    if i%2==0:\n",
    "        card_lat.append(cardinals[i])\n",
    "    else:\n",
    "        card_long.append(cardinals[i])\n",
    "        \n",
    "#concatenating latitudes and longitudes\n",
    "full_longitudes=[]\n",
    "full_latitudes=[]\n",
    "for i in range(len(longitudes)):\n",
    "    full_latitudes.append(str(latitudes[i])+card_lat[i])\n",
    "    full_longitudes.append(str(longitudes[i])+card_long[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regions:\n",
    "i=0\n",
    "regions=[]\n",
    "for reg in geo.find_all(\"td\",class_=\"tb_region\"):\n",
    "    if i<20:\n",
    "        regions.append(reg.get_text())\n",
    "    i+=1\n",
    "    \n",
    "for i in range(len(regions)):\n",
    "    regions[i]=re.sub(r\"\\xa0\",\"\",regions[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarthquakesDF=pd.DataFrame({\"Date\":dates,\n",
    "                            \"Time\":times,\n",
    "                            \"Latitude\":full_latitudes,\n",
    "                            \"Longitude\":full_longitudes,\n",
    "                            \"Region\":regions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>19:12:02.3</td>\n",
       "      <td>36.78N</td>\n",
       "      <td>97.81W</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>19:06:30.0</td>\n",
       "      <td>9.47N</td>\n",
       "      <td>84.69W</td>\n",
       "      <td>COSTA RICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:55:40.4</td>\n",
       "      <td>36.95N</td>\n",
       "      <td>35.58E</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:51:59.1</td>\n",
       "      <td>59.69N</td>\n",
       "      <td>138.92W</td>\n",
       "      <td>SOUTHEASTERN ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:48:58.3</td>\n",
       "      <td>35.64N</td>\n",
       "      <td>4.65W</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:47:21.0</td>\n",
       "      <td>0.46N</td>\n",
       "      <td>126.27E</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:37:47.0</td>\n",
       "      <td>21.58N</td>\n",
       "      <td>121.06E</td>\n",
       "      <td>TAIWAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:28:21.0</td>\n",
       "      <td>2.92S</td>\n",
       "      <td>119.38E</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:24:18.0</td>\n",
       "      <td>0.80S</td>\n",
       "      <td>121.96E</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>18:02:00.0</td>\n",
       "      <td>12.29N</td>\n",
       "      <td>86.96W</td>\n",
       "      <td>NICARAGUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>17:50:20.3</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>18.57E</td>\n",
       "      <td>MONTENEGRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>17:44:12.3</td>\n",
       "      <td>17.98N</td>\n",
       "      <td>66.93W</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>17:18:17.4</td>\n",
       "      <td>59.75N</td>\n",
       "      <td>138.90W</td>\n",
       "      <td>SOUTHEASTERN ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>17:05:19.0</td>\n",
       "      <td>1.30N</td>\n",
       "      <td>122.83E</td>\n",
       "      <td>MINAHASA, SULAWESI, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>17:04:48.0</td>\n",
       "      <td>35.95N</td>\n",
       "      <td>10.08W</td>\n",
       "      <td>AZORES-CAPE ST. VINCENT RIDGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>17:02:23.9</td>\n",
       "      <td>44.15N</td>\n",
       "      <td>115.09W</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>16:56:46.7</td>\n",
       "      <td>19.22N</td>\n",
       "      <td>155.39W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>16:50:51.1</td>\n",
       "      <td>45.89N</td>\n",
       "      <td>7.01E</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>16:43:09.5</td>\n",
       "      <td>19.18N</td>\n",
       "      <td>155.48W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>16:43:06.4</td>\n",
       "      <td>53.30N</td>\n",
       "      <td>167.32W</td>\n",
       "      <td>FOX ISLANDS, ALEUTIAN ISLANDS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Time Latitude Longitude                         Region\n",
       "0   2020-11-16  19:12:02.3   36.78N    97.81W                       OKLAHOMA\n",
       "1   2020-11-16  19:06:30.0    9.47N    84.69W                     COSTA RICA\n",
       "2   2020-11-16  18:55:40.4   36.95N    35.58E                 CENTRAL TURKEY\n",
       "3   2020-11-16  18:51:59.1   59.69N   138.92W            SOUTHEASTERN ALASKA\n",
       "4   2020-11-16  18:48:58.3   35.64N     4.65W            STRAIT OF GIBRALTAR\n",
       "5   2020-11-16  18:47:21.0    0.46N   126.27E                    MOLUCCA SEA\n",
       "6   2020-11-16  18:37:47.0   21.58N   121.06E                  TAIWAN REGION\n",
       "7   2020-11-16  18:28:21.0    2.92S   119.38E            SULAWESI, INDONESIA\n",
       "8   2020-11-16  18:24:18.0    0.80S   121.96E            SULAWESI, INDONESIA\n",
       "9   2020-11-16  18:02:00.0   12.29N    86.96W                      NICARAGUA\n",
       "10  2020-11-16  17:50:20.3   42.59N    18.57E                     MONTENEGRO\n",
       "11  2020-11-16  17:44:12.3   17.98N    66.93W                    PUERTO RICO\n",
       "12  2020-11-16  17:18:17.4   59.75N   138.90W            SOUTHEASTERN ALASKA\n",
       "13  2020-11-16  17:05:19.0    1.30N   122.83E  MINAHASA, SULAWESI, INDONESIA\n",
       "14  2020-11-16  17:04:48.0   35.95N    10.08W  AZORES-CAPE ST. VINCENT RIDGE\n",
       "15  2020-11-16  17:02:23.9   44.15N   115.09W                 SOUTHERN IDAHO\n",
       "16  2020-11-16  16:56:46.7   19.22N   155.39W       ISLAND OF HAWAII, HAWAII\n",
       "17  2020-11-16  16:50:51.1   45.89N     7.01E                 NORTHERN ITALY\n",
       "18  2020-11-16  16:43:09.5   19.18N   155.48W       ISLAND OF HAWAII, HAWAII\n",
       "19  2020-11-16  16:43:06.4   53.30N   167.32W  FOX ISLANDS, ALEUTIAN ISLANDS"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EarthquakesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'\n",
    "response = requests.get(url)\n",
    "wiki = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "names_articles=read_text(wiki.find_all(class_=\"link-box\"))\n",
    "for i in range(len(names_articles)):\n",
    "    names_articles[i]=re.sub(r\"\\xa0\",\"\", names_articles[i])\n",
    "    names_articles[i]=re.sub(r\"\\n\",\": \", names_articles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English: 6183000+ articles',\n",
       " 'Español: 1637000+ artículos',\n",
       " '日本語: 1235000+ 記事',\n",
       " 'Deutsch: 2495000+ Artikel',\n",
       " 'Русский: 1672000+ статей',\n",
       " 'Français: 2262000+ articles',\n",
       " 'Italiano: 1645000+ voci',\n",
       " '中文: 1155000+ 條目',\n",
       " 'Português: 1045000+ artigos',\n",
       " 'Polski: 1435000+ haseł']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'\n",
    "response = requests.get(url)\n",
    "dsets = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "read_text(dsets.select(\"#main-content > div:nth-child(3) > div > ul > li > h3 > a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the top 10 languages by number of native speakers stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "response = requests.get(url)\n",
    "native = BeautifulSoup (response.content,\"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                    Mandarin Chinese\n",
       "2                             Spanish\n",
       "3                             English\n",
       "4     Hindi (Sanskritised Hindustani)\n",
       "5                             Bengali\n",
       "6                          Portuguese\n",
       "7                             Russian\n",
       "8                            Japanese\n",
       "9                     Western Punjabi\n",
       "10                            Marathi\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "data=[]\n",
    "table = native.find('table', attrs={'class':'wikitable sortable'})\n",
    "rows = native.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])\n",
    "    \n",
    "DF=pd.DataFrame(data)\n",
    "DF.drop(0,inplace=True)\n",
    "DF[1].replace(to_replace=\"\\[.*\\]\",value=\"\",inplace=True,regex=True)\n",
    "\n",
    "DF[1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "imdb = BeautifulSoup (response.content,\"html.parser\")\n",
    "#print(imdb.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "stars=read_text(imdb.select(\"tr > td.titleColumn > a\"),\"title\")\n",
    "years=read_text(imdb.select(\"td.titleColumn span.secondaryInfo\"))\n",
    "ratings=read_text(imdb.select(\"td.ratingColumn.imdbRating > strong\"))\n",
    "titles=read_text(imdb.select(\"td.titleColumn > a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.DataFrame({\"Title\":titles,\n",
    "                        \"Year\":years,\n",
    "                        \"Ratings\":ratings,\n",
    "                        \"Stars\":stars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year out of the parentheses\n",
    "movies_df[\"Year\"].replace(to_replace=r\"\\(*\\)*\", value=\"\",regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"(dir.)\"\n",
    "movies_df[\"Stars\"].replace(to_replace=r\"\\(.*\\)+\", value=\"\",regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a column for each person\n",
    "movies_df[['Director','Actor 1', 'Actor 2']] = movies_df.Stars.str.split(pat=\",\",expand=True,)\n",
    "movies_df.drop(\"Stars\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year column to integer\n",
    "movies_df[\"Year\"]=movies_df[\"Year\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor 1</th>\n",
       "      <th>Actor 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cadena perpetua</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>Tim Robbins</td>\n",
       "      <td>Morgan Freeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El padrino</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Marlon Brando</td>\n",
       "      <td>Al Pacino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El padrino: Parte II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>Al Pacino</td>\n",
       "      <td>Robert De Niro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El caballero oscuro</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>Heath Ledger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hombres sin piedad</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>Henry Fonda</td>\n",
       "      <td>Lee J. Cobb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>La batalla de Argel</td>\n",
       "      <td>1966</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Gillo Pontecorvo</td>\n",
       "      <td>Brahim Hadjadj</td>\n",
       "      <td>Jean Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Terminator</td>\n",
       "      <td>1984</td>\n",
       "      <td>8.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>Arnold Schwarzenegger</td>\n",
       "      <td>Linda Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Mandarinas</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Zaza Urushadze</td>\n",
       "      <td>Lembit Ulfsak</td>\n",
       "      <td>Elmo Nüganen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Aladdín</td>\n",
       "      <td>1992</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Ron Clements</td>\n",
       "      <td>Scott Weinger</td>\n",
       "      <td>Robin Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Neon Genesis Evangelion: The End of Evangelion</td>\n",
       "      <td>1997</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Hideaki Anno</td>\n",
       "      <td>Megumi Ogata</td>\n",
       "      <td>Megumi Hayashibara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  Year Ratings  \\\n",
       "0                                   Cadena perpetua  1994     9.2   \n",
       "1                                        El padrino  1972     9.1   \n",
       "2                              El padrino: Parte II  1974     9.0   \n",
       "3                               El caballero oscuro  2008     9.0   \n",
       "4                             12 hombres sin piedad  1957     8.9   \n",
       "..                                              ...   ...     ...   \n",
       "245                             La batalla de Argel  1966     8.0   \n",
       "246                                      Terminator  1984     8.0   \n",
       "247                                      Mandarinas  2013     8.0   \n",
       "248                                         Aladdín  1992     8.0   \n",
       "249  Neon Genesis Evangelion: The End of Evangelion  1997     8.0   \n",
       "\n",
       "                  Director                 Actor 1              Actor 2  \n",
       "0          Frank Darabont              Tim Robbins       Morgan Freeman  \n",
       "1    Francis Ford Coppola            Marlon Brando            Al Pacino  \n",
       "2    Francis Ford Coppola                Al Pacino       Robert De Niro  \n",
       "3       Christopher Nolan           Christian Bale         Heath Ledger  \n",
       "4            Sidney Lumet              Henry Fonda          Lee J. Cobb  \n",
       "..                     ...                     ...                  ...  \n",
       "245      Gillo Pontecorvo           Brahim Hadjadj          Jean Martin  \n",
       "246         James Cameron    Arnold Schwarzenegger       Linda Hamilton  \n",
       "247        Zaza Urushadze            Lembit Ulfsak         Elmo Nüganen  \n",
       "248          Ron Clements            Scott Weinger       Robin Williams  \n",
       "249          Hideaki Anno             Megumi Ogata   Megumi Hayashibara  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "imdb = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "i=0\n",
    "links=[]\n",
    "titles=[]\n",
    "years=[]\n",
    "for tag in imdb.select(\"td.titleColumn  \"):\n",
    "    if i< 10:\n",
    "        links.append(tag.a[\"href\"])\n",
    "        titles.append(tag.a.get_text())\n",
    "        years.append(tag.span.get_text())\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries=[]\n",
    "\n",
    "for link in links:\n",
    "    response = requests.get(\"https://www.imdb.com/\"+link)\n",
    "    imdb = BeautifulSoup (response.content,\"html.parser\")\n",
    "    summaries.append(imdb.select_one(\"div.summary_text\").get_text().strip())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_df = pd.DataFrame({\"Title\": titles,\n",
    "                         \"Year\":  years,\n",
    "                         \"Summary\": summaries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cadena perpetua</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El padrino</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>The aging patriarch of an organized crime dyna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El padrino: Parte II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El caballero oscuro</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hombres sin piedad</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La lista de Schindler</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>In German-occupied Poland during World War II,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El señor de los anillos: El retorno del rey</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>Gandalf and Aragorn lead the World of Men agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>The lives of two mob hitmen, a boxer, a gangst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El bueno, el feo y el malo</td>\n",
       "      <td>(1966)</td>\n",
       "      <td>A bounty hunting scam joins two men in an unea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>El señor de los anillos: La comunidad del anillo</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>A meek Hobbit from the Shire and eight compani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title    Year  \\\n",
       "0                                   Cadena perpetua  (1994)   \n",
       "1                                        El padrino  (1972)   \n",
       "2                              El padrino: Parte II  (1974)   \n",
       "3                               El caballero oscuro  (2008)   \n",
       "4                             12 hombres sin piedad  (1957)   \n",
       "5                             La lista de Schindler  (1993)   \n",
       "6       El señor de los anillos: El retorno del rey  (2003)   \n",
       "7                                      Pulp Fiction  (1994)   \n",
       "8                        El bueno, el feo y el malo  (1966)   \n",
       "9  El señor de los anillos: La comunidad del anillo  (2001)   \n",
       "\n",
       "                                             Summary  \n",
       "0  Two imprisoned men bond over a number of years...  \n",
       "1  The aging patriarch of an organized crime dyna...  \n",
       "2  The early life and career of Vito Corleone in ...  \n",
       "3  When the menace known as the Joker wreaks havo...  \n",
       "4  A jury holdout attempts to prevent a miscarria...  \n",
       "5  In German-occupied Poland during World War II,...  \n",
       "6  Gandalf and Aragorn lead the World of Men agai...  \n",
       "7  The lives of two mob hitmen, a boxer, a gangst...  \n",
       "8  A bounty hunting scam joins two men in an unea...  \n",
       "9  A meek Hobbit from the Shire and eight compani...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city: barcelona\n",
      "Temperature: 289.16\n",
      "Wind speed: 2.1\n",
      "Description: broken clouds\n",
      "Weather: Clouds\n"
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "\n",
    "\n",
    "city = input('Enter the city: ')\n",
    "\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"+\"q=\"+city+\"&appid=204500d7335ede16a33a9c785d5f541d\"\n",
    "response = requests.get(url)\n",
    "print(\"Temperature: \"+str(response.json()[\"main\"][\"temp\"])+\"\\nWind speed: \"+str(response.json()[\"wind\"][\"speed\"])+\"\\nDescription: \"+response.json()[\"weather\"][0][\"description\"]+\"\\nWeather: \"+response.json()[\"weather\"][0][\"main\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'\n",
    "response = requests.get(url)\n",
    "books = BeautifulSoup (response.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = read_text(books.select(\"  h3 >[title]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = read_text(books.select(\"p.instock.availability \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = read_text(books.select(\"p.price_color\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.DataFrame({\"Book \": book_name,\n",
    "                        \"Price\": price,\n",
    "                        \"Stock\": stock})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets ...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A ...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the ...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade ...</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little ...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and ...</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be ...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science ...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Book    Price     Stock\n",
       "0                      A Light in the ...  £51.77  In stock\n",
       "1                      Tipping the Velvet  £53.74  In stock\n",
       "2                              Soumission  £50.10  In stock\n",
       "3                           Sharp Objects  £47.82  In stock\n",
       "4            Sapiens: A Brief History ...  £54.23  In stock\n",
       "5                         The Requiem Red  £22.65  In stock\n",
       "6            The Dirty Little Secrets ...  £33.34  In stock\n",
       "7                 The Coming Woman: A ...  £17.93  In stock\n",
       "8                     The Boys in the ...  £22.60  In stock\n",
       "9                         The Black Maria  £52.15  In stock\n",
       "10  Starving Hearts (Triangular Trade ...  £13.99  In stock\n",
       "11                  Shakespeare's Sonnets  £20.66  In stock\n",
       "12                            Set Me Free  £17.46  In stock\n",
       "13    Scott Pilgrim's Precious Little ...  £52.29  In stock\n",
       "14                      Rip it Up and ...  £35.02  In stock\n",
       "15                  Our Band Could Be ...  £57.25  In stock\n",
       "16                                   Olio  £23.88  In stock\n",
       "17        Mesaerion: The Best Science ...  £37.59  In stock\n",
       "18           Libertarianism for Beginners  £51.33  In stock\n",
       "19                It's Only the Himalayas  £45.17  In stock"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
